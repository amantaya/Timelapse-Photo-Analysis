---
title: "Photo Processing"
author: "Andrew Antaya"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  word_document:
    toc: yes
  citation_package: biblatex
  html_document:
    theme: readable
    toc: yes
    toc_depth: 5
    fig_caption: yes
  pdf_document: default
subtitle:
bibliography: My Library.bib
link-citations: yes
editor_options:
  markdown:
    wrap: 72
---
## Setup

```{r setup, include=FALSE}}

rm(list = ls())

# set the working directory and environment variables
 source("environment.R")

# load in the required packages
source("packages.R")

# load in the required functions
source("functions.R")

knitr::opts_chunk$set(echo = TRUE)

knitr::opts_knit$set(root.dir = currentwd)

flextable::set_flextable_defaults(
  font.size = 10, 
  theme_fun = theme_box,
  text.align = "center",
  fonts_ignore = TRUE,
  background.color = "#EFEFEF")
```

### Load and View Data

Let's read in the RAW photo data from 2017 and 2018, which human observers classified in a custom Excel macro (.xlsm written in VBA). The macro generates data for each image when a human observer selects different options based on what they see in each photo. We saved each of the .xlsm files (each file corresponding to a site and year) as .csv files for ease of use in R and to convert the .xlsm to a non-proprietary format.

For the first step in cleaning up the camera data, we are going to treat all fields with "" (blanks), " " (spaces- typically accidental input which is invisible in Excel), or "NA" (characters), as NA's inside R. This will help us deal with missing information in our dataset.

```{r read csv files in directory}
path_to_csv_files <- fs::dir_ls(file.path(currentwd, 
                                  "data", 
                                  "photo", 
                                  "combined-by-site-year",
                                  "unprocessed"), 
                                regexp = "\\.csv$")

path_to_csv_files
```

The readr package may report problems parsing the data, this is usually OK. Readr is guessing the column type by reading the first 1000 rows in each column. Its expecting the data in each column to be all one type (Logical, Categorical/Factor).
Readr will report a problem anywhere the data types are not the same.

You can check the column specification manually. We can also store this column specification to be specify how the other columns in the data should be read in.

There is a mismatch in the data types in the "TraitB1" column. Some of the columns are numeric, some are character, some are logical (NA). Specify that all of the "TraitB1" column into a character type. The "TraitB1" corresponds to temperature, which was manually entered in by the observer by reading the temperature reported by the camera trap.

```{r set column specification}
col_spec <- cols(
  RecordNumber = col_double(),
  ImageFilename = col_character(),
  ImagePath = col_character(),
  ImageRelative = col_character(),
  ImageSize = col_double(),
  ImageTime = col_character(), # set as character to preserve formatting
  ImageDate = col_character(), # set as character to preserve formatting
  DateTime = col_character(), # set as character to preserve formatting
  ImageAlert = col_logical(),
  Frame1 = col_character(),
  chkFrame1Lock = col_logical(),
  Frame3 = col_character(),
  chkFrame3Lock = col_logical(),
  Conditions1 = col_character(),
  Conditions2 = col_character(),
  Conditions3 = col_character(),
  Conditions4 = col_character(),
  Conditions5 = col_character(),
  Conditions6 = col_character(),
  Conditions7 = col_character(),
  Conditions8 = col_character(),
  chkConditionsLock = col_logical(),
  Trait1 = col_character(),
  Trait2 = col_character(),
  Trait3 = col_character(),
  Trait4 = col_character(),
  chkTraitsLock = col_logical(),
  TraitB1 = col_character(),
  TraitB2 = col_character(),
  TraitB3 = col_character(),
  TraitB4 = col_character(),
  chkTraitsBLock = col_logical(),
  ConditionsB1 = col_character(),
  ConditionsB2 = col_character(),
  ConditionsB3 = col_character(),
  ConditionsB4 = col_character(),
  ConditionsB5 = col_character(),
  ConditionsB6 = col_character(),
  ConditionsB7 = col_logical(),
  ConditionsB8 = col_logical(),
  chkConditionsBLock = col_logical(),
  Species1 = col_character(),
  Species2 = col_character(),
  Species3 = col_character(),
  Species4 = col_character(),
  Species5 = col_character(),
  Species6 = col_character(),
  Species7 = col_character(),
  Species8 = col_character(),
  Species9 = col_character(),
  Species10 = col_character(),
  Species11 = col_character(),
  Species12 = col_character(),
  Species13 = col_character(),
  Species14 = col_character(),
  Species15 = col_character(),
  Species16 = col_character(),
  Species17 = col_character(),
  Species18 = col_character(),
  Species19 = col_character(),
  Species20 = col_character(),
  Species21 = col_character(),
  Species22 = col_character(),
  Species23 = col_character(),
  Species24 = col_character(),
  Species25 = col_character(),
  Species26 = col_character(),
  Species27 = col_character(),
  Species28 = col_character(),
  Species29 = col_character(),
  Species30 = col_character(),
  Species31 = col_character(),
  Species32 = col_character(),
  Species33 = col_character(),
  Species34 = col_character(),
  Species35 = col_character(),
  Species36 = col_character(),
  Species37 = col_character(),
  Species38 = col_character(),
  Species39 = col_character(),
  Species40 = col_character(),
  Species41 = col_character(),
  Species42 = col_character(),
  Species43 = col_character(),
  Species44 = col_character(),
  Species45 = col_character(),
  Species46 = col_character(),
  Species47 = col_character(),
  Species48 = col_character(),
  Species49 = col_character(),
  Species50 = col_character(),
  Species51 = col_character(),
  Species52 = col_character(),
  Species53 = col_character(),
  Species54 = col_character(),
  Species55 = col_character(),
  Species56 = col_character(),
  Species57 = col_character(),
  Species58 = col_character(),
  Species59 = col_character(),
  Species60 = col_character(),
  Species61 = col_character(),
  Species62 = col_character(),
  Species63 = col_character(),
  Species64 = col_character(),
  Species65 = col_character(),
  Species66 = col_character(),
  Species67 = col_character(),
  Species68 = col_character(),
  chkSpeciesLock = col_logical(),
  Count1Species = col_character(),
  Count1Class1 = col_double(),
  Count1Class2 = col_double(),
  Count1Class3 = col_double(),
  Count1Class4 = col_double(),
  Count1Class5 = col_double(),
  Count1Class6 = col_double(),
  Count1Class7 = col_double(),
  Count1Total = col_double(),
  Count2Species = col_character(),
  Count2Class1 = col_double(),
  Count2Class2 = col_double(),
  Count2Class3 = col_double(),
  Count2Class4 = col_double(),
  Count2Class5 = col_double(),
  Count2Class6 = col_double(),
  Count2Class7 = col_double(),
  Count2Total = col_double(),
  Count3Species = col_character(),
  Count3Class1 = col_double(),
  Count3Class2 = col_double(),
  Count3Class3 = col_double(),
  Count3Class4 = col_double(),
  Count3Class5 = col_double(),
  Count3Class6 = col_double(),
  Count3Class7 = col_double(),
  Count3Total = col_double(),
  Count4Species = col_character(),
  Count4Class1 = col_double(),
  Count4Class2 = col_double(),
  Count4Class3 = col_double(),
  Count4Class4 = col_double(),
  Count4Class5 = col_double(),
  Count4Class6 = col_double(),
  Count4Class7 = col_double(),
  Count4Total = col_double(),
  Count5Species = col_character(),
  Count5Class1 = col_double(),
  Count5Class2 = col_double(),
  Count5Class3 = col_double(),
  Count5Class4 = col_double(),
  Count5Class5 = col_double(),
  Count5Class6 = col_double(),
  Count5Class7 = col_double(),
  Count5Total = col_double(),
  chkCountsLock = col_logical(),
  Comments = col_character(),
  chkCommentsLock = col_logical(),
  Flag1 = col_logical(),
  Flag2 = col_logical(),
  Flag3 = col_logical(),
  Flag4 = col_logical(),
  chkFlagsLock = col_logical(),
  chkAllLock = col_logical(),
  LastSavedOn = col_character(),
  chkRelative = col_logical()
)
```

```{r load all csv files}
csv_files <- path_to_csv_files %>% 
  purrr::map(readr::read_csv,
             na = c("", " ", "NA"),
             col_types = col_spec)
```

```{r rename elements in list of csv files }
csv_files <- rename_elements_in_list_of_csv_files(csv_files)
```

```{r print names of elements in list of csv files}
names(csv_files)
```

There was a missing columns from one of the csv files.

```{r}

for (i in 1:length(csv_files)) {

  column_search <- stringr::str_detect(colnames(csv_files[[i]]), "TraitB3")

  if (any(column_search) != TRUE) {

    print(names(csv_files[i]))
    
    break

  } else if (any(column_search) == TRUE) {
    
    print(paste("TraitB3 column is not missing from", names(csv_files[i])))
    
  }
}

```

## Clean Data by Adding Useful Columns and Removing Unuseful Columns

We read in CSV files containing the camera data. Each data frame corresponds to a site and year (e.g., BGW18 is Boggy West Timelapse, data from year 2018). In all of the data frames, each row corresponds to a single image and each column corresponds to a single 'variable'. Some of these 'variables' are actually metadata, such as the file name of the image and the file path.

```{r add site column to all csv files}

for (i in 1:length(csv_files)) {
  
  site_df <- sitecode_constructor(names(csv_files[i]))
  
  csv_files[[i]] <- dplyr::mutate(csv_files[[i]], 
                                  Site = site_df$site, 
                                  .before = RecordNumber)
}
```

```{r add year column to all csv files}
for (i in 1:length(csv_files)) {
  
  year <- stringr::str_extract(names(csv_files[i]), pattern = "\\d{4}")
  
  csv_files[[i]] <- dplyr::mutate(csv_files[[i]], 
                                  Year = year, 
                                  .after = Site)
}
```

## Checking for Comments

```{r get photos with comments}

comments_df <- purrr::map_dfr(csv_files, dplyr::filter, (is.na(Comments) == FALSE))

```

```{r print all photos with comments}
comments_df %>% pull(Comments) %>% tibble()
```

```{r search for comment about cows across fencline}

search_comment <- "across the fenceline in the next pasture to the north"

search_results <- NULL

search_results <- as.list(search_results)

for (i in 1:length(csv_files)) {
  
  search_results[[i]] <- 
    stringr::str_which(csv_files[[i]]$Comments, pattern = search_comment)

  }
```


```{r drop photos with comments about cows across fence line}
for (i in 1:length(csv_files)) {
  
  # check if regex search resulted in different number of list elements
  # stop if not a match
  if (length(csv_files) != length(search_results)) {
    warning("Length of CSV files does not match length of search results")
    break
  }
  
  # run if there was a regex match in search results 
  if (length(search_results[[i]]) != 0) {
    
    csv_files[[i]] <- dplyr::slice(csv_files[[i]], -c(search_results[[i]]))
    
    # print the number of rows dropped from each list element
    # to give a diagnostic output of search results
    n_rows_dropped <- length(search_results[[i]])
    
    print(paste("Dropped", 
                n_rows_dropped, 
                "rows from", 
                names(csv_files[i]), 
                sep = " ")
          )
    }
  }
```

Some of the images we classified in the Excel macro were 'empty' (i.e. the observer could not detect a subject in the image). We want to remove these empty images from analysis.

We're going to use the "Count1Species"" column in each data frame to remove 'empty' photos. The "Count1Species" column corresponds to the 1st detected species in each photo (i.e. the primary species (>50%) if more than one species is detected in a photo). If the image is 'empty' then it will have "NA" for a value in the "Count1Species" column. We're going to use the function complete.cases() to remove all of the rows that have "NA" in the "Count1Species" column. We'll do this for each of the data frames, and save these new data frames into new objects.

```{r drop no detections}

csv_files <- 
  purrr::map(csv_files, tidyr::drop_na, "Count1Species")

```

```{r tally number of species in each csv file}

purrr::map(csv_files, dplyr::count, Count1Species)

```

The data has date and time in separate columns. The lubridate package provides a convenient way to manage time in R. However, first we need to combine the "ImageDate" and "ImageTime" columns.

The 2017 has two columns that have different names than any of the 2018-2020 data. Those columns are "multi" and "water". 

Rename the "TraitB2" and "Trait4" columns from the 2018, 2019, and 2020 data to match the name of the columns in the 2017 data "multi" and "water".

```{r rename TraitB2 and Trait4 cols}

csv_files <- 
  purrr::map(csv_files, dplyr::rename, multi = TraitB2)

csv_files <- 
  purrr::map(csv_files, dplyr::rename, water = Trait4)

```

## Write Data to CSV File

Write out the data frame as a csv file formatted for Excel. We will use this file as an intermediate data file for the next step in our analysis. Having an intermediate data file is helpful because we can perform wrangling steps all at once, and then can use dplyr functions to filter and sort data by site and year. 

```{r write to csv}

list_of_lists <- list(list_of_dataframes = csv_files, 
                      file_names = names(csv_files))

purrr::pmap(list_of_lists, write_csv_purrr)

```
